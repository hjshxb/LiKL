{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from likl.models.line_matcher import WunschLineMatcher\n",
    "from likl.misc.process import (Tp_map_to_line_torch,\n",
    "                            convert_kp2d_pred,\n",
    "                            extract_descriptors)\n",
    "from likl.misc.common import time_sync\n",
    "\n",
    "from likl.dataset.transforms.homo_transforms import sample_homography\n",
    "from likl.dataset.transforms.photometric_transforms import random_saturation\n",
    "from likl.misc.visualize_utils import (plot_images, plot_keypoints, plot_keypoint_matches, plot_lines)\n",
    "from likl.misc.visualize_utils import plot_color_line_matches, plot_line_matches, plot_color_lines\n",
    "from likl.misc.geometry_utils import (warp_points, warp_lines, clip_line_to_boundaries)\n",
    "from likl.misc.metrics import get_line_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ort.get_available_providers())\n",
    "print(ort.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cfg = {\"grid_size\": 8, \"cross_ratio\": 2,\"nms_radius\": 0, \"detect_thresh\": 0.5, \"top_k\": 1000}\n",
    "lines_cfg = {\"score_thresh\": 0.3, \"len_thresh\": 3, \"num_samples\": 5, \"sample_min_dist\": 8}\n",
    "\n",
    "def onnx_inference(input):\n",
    "    ort_sess = ort.InferenceSession('/home/hxb/experiments/likl.onnx')\n",
    "    print(ort_sess.get_providers())\n",
    "    ort_input = {ort_sess.get_inputs()[0].name: input}\n",
    "\n",
    "    t1  = time_sync()\n",
    "    ort_output = ort_sess.run(None, ort_input)\n",
    "    print(\"[Info]: ONNX infer time = \", time_sync() - t1)\n",
    "\n",
    "    line_maps, pts_maps, desc_map = ort_output\n",
    "\n",
    "    pts_maps = torch.from_numpy(pts_maps)\n",
    "    line_maps = torch.from_numpy(line_maps)\n",
    "    desc_map = torch.from_numpy(desc_map)\n",
    "\n",
    "    img_size = input.shape[2:3]\n",
    "    # Get points and desc\n",
    "    batch_pts = []\n",
    "    batch_pts_desc = []\n",
    "    pts = convert_kp2d_pred(pts_maps,\n",
    "                            points_cfg[\"grid_size\"],\n",
    "                            points_cfg[\"cross_ratio\"],\n",
    "                            points_cfg[\"detect_thresh\"],\n",
    "                            points_cfg[\"nms_radius\"])\n",
    "    batch_size = 1\n",
    "    for i in range(batch_size):\n",
    "        pts_pred = pts[i].cpu().numpy()\n",
    "        inds = np.argsort(pts_pred[:, 2])[::-1]\n",
    "        pts_pred = pts_pred[inds[:points_cfg[\"top_k\"]]]\n",
    "        pts_desc = extract_descriptors(\n",
    "            pts_pred[:, :2], desc_map[i], img_size)\n",
    "        batch_pts.append(pts_pred)\n",
    "        batch_pts_desc.append(pts_desc)\n",
    "\n",
    "    # Get line\n",
    "    batch_lines, _, batch_lines_scores = Tp_map_to_line_torch(\n",
    "        line_maps,\n",
    "        score_thresh=lines_cfg[\"score_thresh\"],\n",
    "        len_thresh=lines_cfg[\"len_thresh\"],\n",
    "        image_size=img_size,\n",
    "        valid_mask=None,\n",
    "        with_sig=True)\n",
    "\n",
    "    # Postprocess lines and get line points\n",
    "    batch_lines_desc = []\n",
    "    batch_valid_points = []\n",
    "    for i in range(len(batch_lines)):\n",
    "        lines = batch_lines[i].cpu().numpy()\n",
    "        scores = batch_lines_scores[i].cpu().numpy()\n",
    "\n",
    "        if lines.shape[0] == 0:\n",
    "            batch_lines_desc.append([])\n",
    "            batch_valid_points.append([])\n",
    "            batch_lines[i] = lines\n",
    "            batch_lines_scores[i] = scores\n",
    "            continue\n",
    "        # Get line desc\n",
    "        line_points, valid_points = WunschLineMatcher.sample_line_points(\n",
    "            lines,\n",
    "            lines_cfg[\"num_samples\"],\n",
    "            lines_cfg[\"sample_min_dist\"])\n",
    "        lines_desc = extract_descriptors(\n",
    "            line_points, desc_map[i], img_size)\n",
    "        lines_desc = lines_desc.reshape(\n",
    "            lines.shape[0], lines_cfg[\"num_samples\"], -1)\n",
    "        batch_lines_desc.append(lines_desc.cpu().numpy())\n",
    "        batch_valid_points.append(valid_points)\n",
    "\n",
    "        batch_lines[i] = lines\n",
    "        batch_lines_scores[i] = scores\n",
    "\n",
    "    output = {\n",
    "        \"batch_pts\": batch_pts,\n",
    "        \"batch_pts_desc\": batch_pts_desc,\n",
    "        \"batch_lines\": batch_lines,\n",
    "        \"batch_lines_score\": batch_lines_scores,\n",
    "        \"batch_lines_desc\": batch_lines_desc,\n",
    "        \"batch_valid_points\": batch_valid_points,\n",
    "    }\n",
    "\n",
    "    batch_pts = output[\"batch_pts\"]\n",
    "    batch_pts_desc = output[\"batch_pts_desc\"]\n",
    "    for i in range(len(batch_pts)):\n",
    "        # hw format ==> xy format\n",
    "        batch_pts[i] = batch_pts[i][:, [1, 0, 2]]\n",
    "        batch_pts_desc[i] = batch_pts_desc[i].cpu().numpy()\n",
    "    output[\"batch_pts\"] = batch_pts\n",
    "    output[\"batch_pts_desc\"] = batch_pts_desc\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo = sample_homography([480, 480], inverse=True)\n",
    "img = cv2.imread(\"../asset/00036796.jpg\")\n",
    "img = cv2.resize(img, [480, 480])\n",
    "show_ref_image = img\n",
    "show_target_image = cv2.warpPerspective(show_ref_image, homo, [480, 480], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "show_ref_image = cv2.cvtColor(show_ref_image, cv2.COLOR_BGR2RGB)\n",
    "show_target_image = cv2.cvtColor(show_target_image, cv2.COLOR_BGR2RGB)\n",
    "show_target_image = random_saturation(0.4)(show_target_image)\n",
    "\n",
    "ref_image = show_ref_image.astype(np.float32) / 127.5 - 1\n",
    "target_image = show_target_image.astype(np.float32) / 127.5 - 1\n",
    "\n",
    "outputs1 = onnx_inference(ref_image.transpose(2, 0, 1)[np.newaxis,...])\n",
    "outputs2 = onnx_inference(target_image.transpose(2, 0, 1)[np.newaxis,...])\n",
    "\n",
    "points1, desc1 = outputs1[\"batch_pts\"], outputs1[\"batch_pts_desc\"]\n",
    "points2, desc2 = outputs2[\"batch_pts\"], outputs2[\"batch_pts_desc\"] \n",
    "\n",
    "batch_lines1 = outputs1[\"batch_lines\"][0]\n",
    "batch_lines2 = outputs2[\"batch_lines\"][0]\n",
    "\n",
    "batch_lines1, _ = clip_line_to_boundaries(batch_lines1, show_ref_image.shape[:2], 5)\n",
    "batch_lines2, _ = clip_line_to_boundaries(batch_lines2, show_target_image.shape[:2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_images([show_ref_image, show_target_image], size=1, dpi=600, pad=0.)\n",
    "plot_keypoints([points1[0][:, :2], points2[0][:,  :2]], marker='P', ps=0.5)\n",
    "\n",
    "plot_images([show_ref_image, show_target_image], size=1, dpi=600, pad=0.)\n",
    "plot_lines([batch_lines1[..., ::-1], batch_lines2[..., ::-1]], ps=0.2, lw=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps1, kps2 = points1[0][:, :2], points2[0][:, :2]\n",
    "des1, des2 = desc1[0], desc2[0]\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "putative_match = matcher.match(des1, des2)\n",
    "query_idx = np.array([m.queryIdx for m in putative_match])\n",
    "match_keypoints = kps1[query_idx, :]\n",
    "train_idx = np.array([m.trainIdx for m in putative_match])\n",
    "match_warped_keypoints = kps2[train_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots_adjust()\n",
    "plot_images([show_ref_image, show_target_image])\n",
    "# plot_images([data[\"ref_image\"].permute(1, 2, 0), data[\"target_image\"].permute(1, 2, 0)])\n",
    "plot_keypoint_matches(match_keypoints, match_warped_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gt_match_warped_kps = warp_points(match_keypoints, homo, \"xy\")\n",
    "dist = np.linalg.norm(gt_match_warped_kps - match_warped_keypoints, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dist <= 3\n",
    "print(\"putative_match: \", match_keypoints.shape[0])\n",
    "inlier_match_keypoints = match_keypoints[idx]\n",
    "error_match_keypoints = match_keypoints[~idx]\n",
    "inlier_match_warped_keypoints = match_warped_keypoints[idx]\n",
    "error_match_warped_keypoints = match_warped_keypoints[~idx]\n",
    "print(\"inlier_match: \", inlier_match_keypoints.shape[0])\n",
    "print(\"MMA: \", inlier_match_keypoints.shape[0] / match_keypoints.shape[0])\n",
    "color = [\"red\"] * len(match_keypoints)\n",
    "for i in range(len(idx)):\n",
    "    if idx[i]:\n",
    "        color[i] = \"lime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([show_ref_image, \n",
    "             show_target_image], size=1, dpi=600, pad=0.)\n",
    "\n",
    "plot_keypoints([points1[0][:, :2], points2[0][:,  :2]], ps=0.5, marker=\"P\", colors=\"blue\")\n",
    "\n",
    "plot_keypoints([inlier_match_keypoints, inlier_match_warped_keypoints], ps=0.5, marker=\"P\", colors=\"lime\")\n",
    "plot_keypoints([error_match_keypoints, error_match_warped_keypoints], ps=0.5, marker=\"P\", colors=\"red\")\n",
    "plot_keypoint_matches(match_keypoints[:], match_warped_keypoints[:], color=color[:], lw=0.15, ps=0.0001, a=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = WunschLineMatcher(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_desc1 = outputs1[\"batch_lines_desc\"][0]\n",
    "line_desc2 = outputs2[\"batch_lines_desc\"][0]\n",
    "print(line_desc1.shape)\n",
    "valid_points1 = outputs1[\"batch_valid_points\"][0]\n",
    "valid_points2 = outputs2[\"batch_valid_points\"][0]\n",
    "line_matches = matcher.match(torch.from_numpy(line_desc1), torch.from_numpy(line_desc2), \n",
    "                             torch.from_numpy(valid_points1), torch.from_numpy(valid_points2))\n",
    "\n",
    "valid_matches = line_matches != -1\n",
    "match_indices = line_matches[valid_matches]\n",
    "print(match_indices)\n",
    "matched_lines1 = batch_lines1[valid_matches]\n",
    "matched_lines2 = batch_lines2[match_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([show_ref_image, show_target_image])\n",
    "colors = plot_color_line_matches([matched_lines1[..., ::-1], matched_lines2[..., ::-1]], lw=2, return_color=True)\n",
    "# plot_line_matches(matched_lines1[..., ::-1].mean(1), matched_lines2[..., ::-1].mean(1), color=colors, lw=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_matched_lines1 = warp_lines(matched_lines1, homo)\n",
    "warped_matched_lines1, mask = clip_line_to_boundaries(warped_matched_lines1, show_target_image.shape[:2], 5)\n",
    "warped_matched_lines1 = warped_matched_lines1[mask]\n",
    "matched_lines2 = matched_lines2[mask]\n",
    "matched_lines1 = matched_lines1[mask]\n",
    "line_dist = get_line_distance(\n",
    "            warped_matched_lines1, matched_lines2, \"orth\")\n",
    "idx = (np.min(line_dist, axis=1)) < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "def plot_line_matches(kpts0, kpts1, color=None, lw=1.5, indices=(0, 1), a=1., save_file=None):\n",
    "    \"\"\"Plot matches for a pair of existing images, parametrized by their middle point.\n",
    "    Args:\n",
    "        kpts0, kpts1: corresponding middle points of the lines of size (N, 2).\n",
    "        color: color of each match, string or RGB tuple. Random if not given.\n",
    "        lw: width of the lines.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "        a: alpha opacity of the match lines.\n",
    "    \"\"\"\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    ax0, ax1 = ax[indices[0]], ax[indices[1]]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    assert len(kpts0) == len(kpts1)\n",
    "    if color is None:\n",
    "        color = matplotlib.cm.hsv(np.random.rand(len(kpts0))).tolist()\n",
    "    elif len(color) > 0 and not isinstance(color, (tuple, list)):\n",
    "        color = [color] * len(kpts0)\n",
    "    if lw > 0:\n",
    "        # transform the points into the figure coordinate system\n",
    "        transFigure = fig.transFigure.inverted()\n",
    "        fkpts0 = transFigure.transform(ax0.transData.transform(kpts0))\n",
    "        fkpts1 = transFigure.transform(ax1.transData.transform(kpts1))\n",
    "        fig.lines += [matplotlib.lines.Line2D(\n",
    "            (fkpts0[i, 0], fkpts1[i, 0]), (fkpts0[i, 1], fkpts1[i, 1]),\n",
    "            zorder=1, transform=fig.transFigure, c=color[i], linewidth=lw,\n",
    "            alpha=a)\n",
    "            for i in range(len(kpts0))]\n",
    "\n",
    "    # freeze the axes to prevent the transform to change\n",
    "    ax0.autoscale(enable=False)\n",
    "    ax1.autoscale(enable=False)\n",
    "    if save_file:\n",
    "        fig.savefig(save_file, bbox_inches='tight', pad_inches=0.0)\n",
    "\n",
    "\n",
    "plot_images([show_ref_image, \n",
    "             show_target_image],\n",
    "             size=1,\n",
    "             dpi=600, pad=0.)\n",
    "inlier_match_lines1 = matched_lines1[idx]\n",
    "error_match_lines1 = matched_lines1[~idx]\n",
    "inlier_match_lines2 = matched_lines2[idx]\n",
    "error_match_lines2 = matched_lines2[~idx]\n",
    "\n",
    "plot_lines([batch_lines1[..., ::-1], batch_lines2[..., ::-1]], line_colors=\"blue\", point_colors=\"blue\", ps=0.1, lw=0.2)\n",
    "\n",
    "\n",
    "colors = [\"red\"] * len(matched_lines1)\n",
    "for i in range(len(matched_lines1)):\n",
    "    if idx[i]:\n",
    "        colors[i] = \"lime\"\n",
    "plot_lines([inlier_match_lines1[..., ::-1], inlier_match_lines2[..., ::-1]], line_colors=\"lime\", point_colors=\"lime\", ps=0.1, lw=0.2)\n",
    "plot_lines([error_match_lines1[..., ::-1], error_match_lines2[..., ::-1]], line_colors=\"red\", point_colors=\"red\", ps=0.1, lw=0.2)\n",
    "plot_line_matches(matched_lines1[..., ::-1].mean(1), matched_lines2[..., ::-1].mean(1), color=colors, lw=0.2, a=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
