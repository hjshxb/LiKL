{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import yaml\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from likl.dataset.transforms.homo_transforms import sample_homography\n",
    "from likl.dataset.transforms.photometric_transforms import random_saturation\n",
    "from likl.misc.visualize_utils import (plot_images, plot_keypoints, plot_keypoint_matches, plot_lines)\n",
    "from likl.misc.visualize_utils import plot_color_line_matches, plot_line_matches, plot_color_lines\n",
    "from likl.misc.geometry_utils import (warp_points, warp_lines, clip_line_to_boundaries)\n",
    "from likl.misc.metrics import get_line_distance\n",
    "from likl.config.misc import load_config\n",
    "\n",
    "from demo import LiklDetector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_cfg = load_config(\"../likl/config/extract_cfg.yaml\")\n",
    "detector_model = LiklDetector(**extract_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo = sample_homography([480, 480], inverse=True)\n",
    "img = cv2.imread(\"../asset/00036796.jpg\")\n",
    "img = cv2.resize(img, [480, 480])\n",
    "show_ref_image = img\n",
    "show_target_image = cv2.warpPerspective(show_ref_image, homo, [480, 480], flags=cv2.INTER_LINEAR)\n",
    "show_target_image = random_saturation(0.4)(show_target_image)\n",
    "\n",
    "ref_image = cv2.cvtColor(show_ref_image, cv2.COLOR_BGR2RGB)\n",
    "target_image = cv2.cvtColor(show_target_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "ref_image = ref_image.astype(np.float32) / 127.5 - 1\n",
    "target_image = target_image.astype(np.float32) / 127.5 - 1\n",
    "\n",
    "outputs1 = detector_model.run(ref_image, return_type=\"dict\")\n",
    "outputs2 = detector_model.run(target_image, return_type=\"dict\")\n",
    "points1, desc1 = outputs1[\"batch_pts\"], outputs1[\"batch_pts_desc\"]\n",
    "points2, desc2 = outputs2[\"batch_pts\"], outputs2[\"batch_pts_desc\"] \n",
    "\n",
    "batch_lines1 = outputs1[\"batch_lines\"][0]\n",
    "batch_lines2 = outputs2[\"batch_lines\"][0]\n",
    "\n",
    "batch_lines1, _ = clip_line_to_boundaries(batch_lines1, show_ref_image.shape[:2], 5)\n",
    "batch_lines2, _ = clip_line_to_boundaries(batch_lines2, show_target_image.shape[:2], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_images([show_ref_image, show_target_image], size=1, dpi=600, pad=0.)\n",
    "plot_keypoints([points1[0][:, :2], points2[0][:,  :2]], marker='P', ps=0.5)\n",
    "\n",
    "plot_images([show_ref_image, show_target_image], size=1, dpi=600, pad=0.)\n",
    "plot_lines([batch_lines1[..., ::-1], batch_lines2[..., ::-1]], ps=0.2, lw=0.4)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps1, kps2 = points1[0][:, :2], points2[0][:, :2]\n",
    "des1, des2 = desc1[0], desc2[0]\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "putative_match = matcher.match(des1, des2)\n",
    "query_idx = np.array([m.queryIdx for m in putative_match])\n",
    "match_keypoints = kps1[query_idx, :]\n",
    "train_idx = np.array([m.trainIdx for m in putative_match])\n",
    "match_warped_keypoints = kps2[train_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots_adjust()\n",
    "plot_images([show_ref_image, show_target_image])\n",
    "# plot_images([data[\"ref_image\"].permute(1, 2, 0), data[\"target_image\"].permute(1, 2, 0)])\n",
    "plot_keypoint_matches(match_keypoints, match_warped_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gt_match_warped_kps = warp_points(match_keypoints, homo, \"xy\")\n",
    "dist = np.linalg.norm(gt_match_warped_kps - match_warped_keypoints, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = dist <= 3\n",
    "print(\"putative_match: \", match_keypoints.shape[0])\n",
    "inlier_match_keypoints = match_keypoints[idx]\n",
    "error_match_keypoints = match_keypoints[~idx]\n",
    "inlier_match_warped_keypoints = match_warped_keypoints[idx]\n",
    "error_match_warped_keypoints = match_warped_keypoints[~idx]\n",
    "print(\"inlier_match: \", inlier_match_keypoints.shape[0])\n",
    "print(\"MMA: \", inlier_match_keypoints.shape[0] / match_keypoints.shape[0])\n",
    "color = [\"red\"] * len(match_keypoints)\n",
    "for i in range(len(idx)):\n",
    "    if idx[i]:\n",
    "        color[i] = \"lime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([show_ref_image, \n",
    "             show_target_image], size=1, dpi=600, pad=0.)\n",
    "\n",
    "plot_keypoints([points1[0][:, :2], points2[0][:,  :2]], ps=0.5, marker=\"P\", colors=\"blue\")\n",
    "\n",
    "plot_keypoints([inlier_match_keypoints, inlier_match_warped_keypoints], ps=0.5, marker=\"P\", colors=\"lime\")\n",
    "plot_keypoints([error_match_keypoints, error_match_warped_keypoints], ps=0.5, marker=\"P\", colors=\"red\")\n",
    "plot_keypoint_matches(match_keypoints[:], match_warped_keypoints[:], color=color[:], lw=0.15, ps=0.0001, a=0.7,\n",
    "                      save_file=\"../asset/points_match.png\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from likl.models.line_matcher import WunschLineMatcher\n",
    "matcher = WunschLineMatcher(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_desc1 = outputs1[\"batch_lines_desc\"][0]\n",
    "line_desc2 = outputs2[\"batch_lines_desc\"][0]\n",
    "print(line_desc1.shape)\n",
    "valid_points1 = outputs1[\"batch_valid_points\"][0]\n",
    "valid_points2 = outputs2[\"batch_valid_points\"][0]\n",
    "line_matches = matcher.match(torch.from_numpy(line_desc1), torch.from_numpy(line_desc2), \n",
    "                             torch.from_numpy(valid_points1), torch.from_numpy(valid_points2))\n",
    "\n",
    "valid_matches = line_matches != -1\n",
    "match_indices = line_matches[valid_matches]\n",
    "print(match_indices)\n",
    "matched_lines1 = batch_lines1[valid_matches]\n",
    "matched_lines2 = batch_lines2[match_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images([show_ref_image, show_target_image])\n",
    "colors = plot_color_line_matches([matched_lines1[..., ::-1], matched_lines2[..., ::-1]], lw=2, return_color=True)\n",
    "# plot_line_matches(matched_lines1[..., ::-1].mean(1), matched_lines2[..., ::-1].mean(1), color=colors, lw=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_matched_lines1 = warp_lines(matched_lines1, homo)\n",
    "warped_matched_lines1, mask = clip_line_to_boundaries(warped_matched_lines1, show_target_image.shape[:2], 5)\n",
    "warped_matched_lines1 = warped_matched_lines1[mask]\n",
    "matched_lines2 = matched_lines2[mask]\n",
    "matched_lines1 = matched_lines1[mask]\n",
    "line_dist = get_line_distance(\n",
    "            warped_matched_lines1, matched_lines2, \"orth\")\n",
    "idx = (np.min(line_dist, axis=1)) < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "def plot_line_matches(kpts0, kpts1, color=None, lw=1.5, indices=(0, 1), a=1., save_file=None):\n",
    "    \"\"\"Plot matches for a pair of existing images, parametrized by their middle point.\n",
    "    Args:\n",
    "        kpts0, kpts1: corresponding middle points of the lines of size (N, 2).\n",
    "        color: color of each match, string or RGB tuple. Random if not given.\n",
    "        lw: width of the lines.\n",
    "        indices: indices of the images to draw the matches on.\n",
    "        a: alpha opacity of the match lines.\n",
    "    \"\"\"\n",
    "    fig = plt.gcf()\n",
    "    ax = fig.axes\n",
    "    assert len(ax) > max(indices)\n",
    "    ax0, ax1 = ax[indices[0]], ax[indices[1]]\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    assert len(kpts0) == len(kpts1)\n",
    "    if color is None:\n",
    "        color = matplotlib.cm.hsv(np.random.rand(len(kpts0))).tolist()\n",
    "    elif len(color) > 0 and not isinstance(color, (tuple, list)):\n",
    "        color = [color] * len(kpts0)\n",
    "    if lw > 0:\n",
    "        # transform the points into the figure coordinate system\n",
    "        transFigure = fig.transFigure.inverted()\n",
    "        fkpts0 = transFigure.transform(ax0.transData.transform(kpts0))\n",
    "        fkpts1 = transFigure.transform(ax1.transData.transform(kpts1))\n",
    "        fig.lines += [matplotlib.lines.Line2D(\n",
    "            (fkpts0[i, 0], fkpts1[i, 0]), (fkpts0[i, 1], fkpts1[i, 1]),\n",
    "            zorder=1, transform=fig.transFigure, c=color[i], linewidth=lw,\n",
    "            alpha=a)\n",
    "            for i in range(len(kpts0))]\n",
    "\n",
    "    # freeze the axes to prevent the transform to change\n",
    "    ax0.autoscale(enable=False)\n",
    "    ax1.autoscale(enable=False)\n",
    "    if save_file:\n",
    "        fig.savefig(save_file, bbox_inches='tight', pad_inches=0.0)\n",
    "\n",
    "\n",
    "plot_images([show_ref_image, \n",
    "             show_target_image],\n",
    "             size=1,\n",
    "             dpi=600, pad=0.)\n",
    "inlier_match_lines1 = matched_lines1[idx]\n",
    "error_match_lines1 = matched_lines1[~idx]\n",
    "inlier_match_lines2 = matched_lines2[idx]\n",
    "error_match_lines2 = matched_lines2[~idx]\n",
    "\n",
    "plot_lines([batch_lines1[..., ::-1], batch_lines2[..., ::-1]], line_colors=\"blue\", point_colors=\"blue\", ps=0.1, lw=0.2)\n",
    "\n",
    "\n",
    "colors = [\"red\"] * len(matched_lines1)\n",
    "for i in range(len(matched_lines1)):\n",
    "    if idx[i]:\n",
    "        colors[i] = \"lime\"\n",
    "plot_lines([inlier_match_lines1[..., ::-1], inlier_match_lines2[..., ::-1]], line_colors=\"lime\", point_colors=\"lime\", ps=0.1, lw=0.2)\n",
    "plot_lines([error_match_lines1[..., ::-1], error_match_lines2[..., ::-1]], line_colors=\"red\", point_colors=\"red\", ps=0.1, lw=0.2)\n",
    "plot_line_matches(matched_lines1[..., ::-1].mean(1), matched_lines2[..., ::-1].mean(1), color=colors, lw=0.2, a=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SOLD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "620658faaa9815e68c0cf2ebc9620d278ebf493bfcde0e25217af190d7b351a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
